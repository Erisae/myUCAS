{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTurn: 1 -->\nTrain Loss: 1.0265072461520529e-05\nTest Loss: 0.0007928679477987477\nTrain Accuracy: 0.5576474780620351\nTest Accuracy: 0.5091743119266054\n\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x-np.max(x,axis = 0))\n",
    "    total = np.sum(x_exp,axis=0) # 列\n",
    "    return x_exp / total\n",
    "    \n",
    "\n",
    "# 线性模型\n",
    "def linear_model(w,b,x):\n",
    "    return softmax(np.dot(w.T,x)+b)\n",
    "# 交叉熵\n",
    "def cross_entropy(y, y_hat):\n",
    "    return - np.sum(y*np.log(y_hat+np.exp(-7)))\n",
    "\n",
    "# 梯度下降\n",
    "def sgd(w, b,x, y, alpha=0.01): # aaa\n",
    "    batch_size = x.shape[1]\n",
    "    lm = linear_model(w,b,x)\n",
    "    dw = np.dot((y - lm),x.T)\n",
    "    db = np.sum(y - lm, axis = 1,keepdims = True) # aaa\n",
    "    w_o = w + alpha*dw.T/batch_size\n",
    "    b_o = b + alpha*db/batch_size\n",
    "    return w_o,b_o\n",
    "\n",
    "def get_minibatch(epoch,batch_size,x,y):\n",
    "    rounds = 67349 / batch_size\n",
    "    index1 = int((epoch % rounds) * batch_size)\n",
    "    index2 = int((epoch % rounds + 1) * batch_size)\n",
    "    return x[:,index1 :index2], y[:,index1:index2]\n",
    "\n",
    "\n",
    "x = np.load(\"sst-train-x.npy\",allow_pickle=True) \n",
    "y = np.load(\"sst-train-y.npy\",allow_pickle=True)\n",
    "x_t  = np.load(\"sst-test-x.npy\",allow_pickle=True)\n",
    "y_t  = np.load(\"sst-test-y.npy\",allow_pickle=True)\n",
    "x = x.T.astype(\"float\")\n",
    "x_t  = x_t.T.astype(\"float\")\n",
    "y = y.T\n",
    "y_t = y_t.T\n",
    "\n",
    "# 画图\n",
    "tstl = []\n",
    "trnl = []\n",
    "tacc = []\n",
    "# 初始化数据\n",
    "\n",
    "epochs = 10000 # aaa\n",
    "\n",
    "w_dat = np.random.randint(1,100,size=(700,2))\n",
    "w = w_dat / w_dat.sum(axis=0)\n",
    "b = np.zeros((2,1))\n",
    "'''\n",
    "\n",
    "b = np.load(\"sst-linear_b.npy\",allow_pickle = True)\n",
    "w = np.load(\"sst-linear_w.npy\",allow_pickle = True)\n",
    "'''\n",
    "batch_size = 67349 # aaa 67349\n",
    "batch_size_t = 872\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    # 获得用于训练的minibatch\n",
    "    minibatch_x,minibatch_y = get_minibatch(epoch,batch_size,x,y)\n",
    "    # 初始化训练损失\n",
    "    l = linear_model(w,b, minibatch_x)\n",
    "    loss = cross_entropy(minibatch_y, l)\n",
    "    # 累加每个元素的损失\n",
    "    train_loss = loss / batch_size\n",
    "    trnl.append(train_loss)\n",
    "        \n",
    "    # 梯度下降\n",
    "    w,b = sgd(w,b,minibatch_x, minibatch_y)\n",
    "\n",
    "    # 测试\n",
    "    # 注意：测试集不需要梯度，也不需要梯度清零、反向传播、梯度下降\n",
    "    l_t = linear_model(w,b, x_t)\n",
    "    loss_t = cross_entropy(y_t, l_t)\n",
    "    test_loss = loss_t / batch_size_t\n",
    "    tstl.append(test_loss)\n",
    "        \n",
    "    # 累加计算正确的个数的平均值\n",
    "    acc = (np.argmax(l_t,axis=0) == np.argmax(y_t,axis=0)).sum()\n",
    "    tacc.append(acc / batch_size_t)\n",
    "\n",
    "    # 每训练三次就输出一次性能\n",
    "    if epoch % 100 == 0: # aaa\n",
    "        train_y = linear_model(w,b, x)\n",
    "        train_acc = (np.argmax(train_y,axis=0) == np.argmax(y,axis=0)).sum() / 67349\n",
    "       # 输出\n",
    "        print(f\"\\nTurn: {epoch // 1 + 1} -->\\n\"\n",
    "            f\"Train Loss: {train_loss / batch_size}\\n\"\n",
    "            f\"Test Loss: {test_loss / batch_size_t}\\n\"\n",
    "            f\"Train Accuracy: {train_acc}\\n\"\n",
    "            f\"Test Accuracy: {acc / batch_size_t}\\n\")\n",
    "        np.save(\"sst-linear_w\",w)\n",
    "        np.save(\"sst-linear_b\",b)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(tstl,color='b')#画在图1上\n",
    "plt.plot(trnl,color='r')\n",
    "plt.savefig('linear_loss_r.png')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot()#画在图2上，且不在一个窗口              \n",
    "plt.plot(tacc,color='b')\n",
    "plt.savefig('linear_acc_r.png')\n",
    "print(\"Over\")\n"
   ]
  }
 ]
}